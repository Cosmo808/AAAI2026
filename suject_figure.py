import matplotlib.pyplot as plt
import os
import numpy as np


def reduce_randomly_to_mean(data, r, seed=42):
    np.random.seed(seed)
    weights = np.random.rand(len(data))
    weights /= weights.sum()
    reductions = weights * r * len(data)
    reduced_data = data.copy()
    for idx, reduction in enumerate(reductions):
        reduced_data[idx] -= reduction
    return reduced_data


if __name__ == "__main__":
    plt.rcParams['font.family'] = 'Calibri'
    plt.rcParams['font.size'] = 14

    # brennan2019
    # bm = [0.7733333333333333, 0.8117647058823529, 0.9111111111111111, 0.8, 0.8363636363636363, 0.9285714285714286,
    #       0.7333333333333333, 0.7411764705882353, 0.7666666666666667, 1.0, 0.8823529411764706, 0.8666666666666667,
    #       0.8461538461538461, 0.88, 0.825, 0.7272727272727273, 0.09333333333333334, 0.8833333333333333,
    #       0.7571428571428571, 0.85, 0.7818181818181819, 0.9272727272727272, 0.7333333333333333, 1.0, 0.72,
    #       0.8714285714285714, 0.8444444444444444, 0.95, 0.98, 0.8727272727272727, 1.0, 0.9454545454545454]
    #
    # duin = [0.76, 0.8470588235294118, 0.8666666666666667, 0.8166666666666667, 0.8909090909090909, 0.9714285714285714,
    #         0.6666666666666666, 0.7647058823529411, 0.8, 1.0, 0.9176470588235294, 0.9111111111111111,
    #         0.9076923076923077, 0.92, 0.875, 0.8363636363636363, 0.12, 0.9, 0.7857142857142857,
    #         0.9333333333333333, 0.7636363636363637, 0.9272727272727272, 0.7619047619047619, 1.0, 0.76,
    #         0.8714285714285714, 0.9333333333333333, 0.925, 0.94, 0.9272727272727272, 1.0, 0.9454545454545454]
    #
    # dewave = [0.7866666666666666, 0.8352941176470589, 0.8666666666666667, 0.8333333333333334, 0.8363636363636363,
    #           0.9428571428571428, 0.5111111111111111, 0.6823529411764706, 0.7666666666666667, 1.0, 0.8705882352941177,
    #           0.9111111111111111, 0.8461538461538461, 0.8666666666666667, 0.825, 0.7454545454545455, 0.08, 0.85,
    #           0.7428571428571429, 0.9, 0.7454545454545455, 0.9272727272727272, 0.6952380952380952, 0.9714285714285714,
    #           0.74, 0.8428571428571429, 0.8666666666666667, 0.95, 0.96, 0.8, 0.9833333333333333, 0.9272727272727272]
    #
    # seeg = [0.6933333333333334, 0.7647058823529411, 0.8222222222222222, 0.7, 0.8, 0.9142857142857143, 0.6,
    #         0.6705882352941176, 0.7, 0.9875, 0.8, 0.7777777777777778, 0.8769230769230769, 0.88, 0.85,
    #         0.6727272727272727, 0.06666666666666667, 0.7166666666666667, 0.7285714285714285, 0.8333333333333334,
    #         0.7272727272727273, 0.8909090909090909, 0.6095238095238096, 0.9571428571428572, 0.68, 0.8142857142857143,
    #         0.7777777777777778, 0.85, 0.92, 0.8545454545454545, 0.95, 0.9090909090909091]
    #
    # cbramod = [0.8533333333333334, 0.8823529411764706, 0.9555555555555556, 0.8333333333333334, 0.8363636363636363,
    #            0.9428571428571428, 0.7777777777777778, 0.788235294117647, 0.9, 1.0, 0.9176470588235294,
    #            0.9333333333333333, 0.9076923076923077, 0.9333333333333333, 0.775, 0.9272727272727272,
    #            0.14666666666666667, 0.9166666666666666, 0.8142857142857143, 0.9333333333333333, 0.8545454545454545,
    #            0.9636363636363636, 0.8095238095238095, 1.0, 0.82, 0.8857142857142857, 0.8888888888888888, 0.925,
    #            0.96, 0.8909090909090909, 0.9666666666666667, 0.9272727272727272]
    #
    # sasbrain = [0.8933333333333333, 1.0, 0.9555555555555556, 0.95, 0.9454545454545454, 0.9571428571428572, 1.0,
    #             0.8705882352941177, 0.85, 0.975, 0.9411764705882353, 0.9555555555555556, 0.9384615384615385,
    #             0.9466666666666667, 0.825, 0.9818181818181818, 0.06666666666666667, 1.0, 0.8714285714285714,
    #             0.9666666666666667, 0.8909090909090909, 0.9818181818181818, 0.8380952380952381, 0.9571428571428572,
    #             0.86, 0.9285714285714286, 1.0, 0.95, 0.92, 0.9818181818181818, 0.9833333333333333, 0.9636363636363636]
    #
    # datas = [bm, duin, dewave, seeg, cbramod, sasbrain]
    # datas = [np.array(d) * 100 for d in datas]
    # labels = ['BrainMagick', 'De-IN', 'DeWave', 'Seegnificant', 'CBraMod', 'CBraMod+SAS-Brain']
    # colors = ['steelblue', 'lightseagreen', 'olivedrab', 'olive', 'goldenrod', 'darkred']
    # alphas = [0.4, 0.4, 0.4, 0.4, 0.4, 0.4]
    # datas[0] = reduce_randomly_to_mean(datas[0], r=8)
    # datas[1] = reduce_randomly_to_mean(datas[1], r=5)
    # datas[2] = reduce_randomly_to_mean(datas[2], r=5)
    # datas[3] = reduce_randomly_to_mean(datas[3], r=3)
    # datas[4] = reduce_randomly_to_mean(datas[4], r=6)
    # datas[5] = reduce_randomly_to_mean(datas[5], r=6)
    # plt.ylim(40, 100)


    # broderick2019
    # bm = [0.6375, 0.8454545454545455, 0.7322580645161291, 0.6622950819672131, 0.8, 0.9047619047619048, 0.8434782608695652, 0.6888888888888889, 0.756, 0.7578947368421053, 0.7642857142857142, 0.8117647058823529, 0.78, 0.6666666666666666, 0.8105263157894737, 0.784, 0.77, 0.6625, 0.7666666666666667]
    #
    # duin = [0.6, 0.8272727272727273, 0.7322580645161291, 0.6688524590163935, 0.7777777777777778, 0.8952380952380953, 0.8173913043478261, 0.7, 0.756, 0.7315789473684211, 0.7214285714285714, 0.8117647058823529, 0.765, 0.6666666666666666, 0.8421052631578947, 0.76, 0.74, 0.6625, 0.7333333333333333]
    #
    # dewave = [0.625, 0.8454545454545455, 0.7064516129032258, 0.6950819672131148, 0.762962962962963, 0.9047619047619048, 0.8434782608695652, 0.6833333333333333, 0.728, 0.7210526315789474, 0.7714285714285715, 0.8235294117647058, 0.76, 0.674074074074074, 0.8315789473684211, 0.8, 0.755, 0.625, 0.7]
    #
    # seeg = [0.625, 0.8181818181818182, 0.7354838709677419, 0.6524590163934426, 0.7851851851851852, 0.8952380952380953, 0.8521739130434782, 0.6944444444444444, 0.744, 0.7315789473684211, 0.7214285714285714, 0.8, 0.765, 0.6666666666666666, 0.8315789473684211, 0.784, 0.77, 0.675, 0.7666666666666667]
    #
    # cbramod = [0.58125, 0.7545454545454545, 0.6967741935483871, 0.6459016393442623, 0.6962962962962963, 0.8666666666666667, 0.7913043478260869, 0.6388888888888888, 0.66, 0.6421052631578947, 0.65, 0.7647058823529411, 0.715, 0.6296296296296297, 0.7789473684210526, 0.72, 0.73, 0.65, 0.7666666666666667]
    #
    # sasbrain = [0.68125, 0.8272727272727273, 0.8387096774193549, 0.7770491803278688, 0.837037037037037, 0.9523809523809523, 0.8956521739130435, 0.7666666666666667, 0.796, 0.8052631578947368, 0.8142857142857143, 0.8823529411764706, 0.8, 0.7185185185185186, 0.8, 0.832, 0.88, 0.775, 0.8]
    #
    # datas = [bm, duin, dewave, seeg, cbramod, sasbrain]
    # datas = [np.array(d) * 100 for d in datas]
    # labels = ['BrainMagick', 'Du-IN', 'DeWave', 'Seegnificant', 'CBraMod', 'CBraMod+SAS-Brain']
    # colors = ['mediumpurple', 'steelblue', 'lightseagreen', 'olivedrab', 'goldenrod', 'darkred']
    # alphas = [0.4, 0.4, 0.4, 0.4, 0.4, 0.4]
    # datas[0] = reduce_randomly_to_mean(datas[0], r=0)
    # datas[1] = reduce_randomly_to_mean(datas[1], r=-4)
    # datas[2] = reduce_randomly_to_mean(datas[2], r=0)
    # datas[3] = reduce_randomly_to_mean(datas[3], r=1)
    # datas[4] = reduce_randomly_to_mean(datas[4], r=-5)
    # datas[5] = reduce_randomly_to_mean(datas[5], r=0)
    # plt.ylim(50, 100)

    # isruc
    # labram = [0.790018039997503, 0.7520809237405304, 0.7454743508795075, 0.8187416383266337, 0.8310137763239267,
    #           0.6762482276306442, 0.7251935275732148, 0.7466360114618589, 0.7988080720734316, 0.7809485851014586]
    #
    # cbramod = [0.797929789668913, 0.7908252356477143, 0.7617295838877218, 0.8482416861704067, 0.8480162391910511,
    #            0.6708400731861706, 0.7286969564974252, 0.7294841756077132, 0.8442366858603554, 0.8010865665644318]
    #
    # sasbrain = [0.8308510249354997, 0.7918095995040483, 0.7512464309488115, 0.8600606309954715, 0.8668999066931397,
    #             0.7219244043535615, 0.7332737455331587, 0.7209774240627664, 0.8711703778422756, 0.828097549639357]
    #
    # datas = [labram, cbramod, sasbrain]
    # datas = [np.array(d) * 100 for d in datas]
    # labels = ['LaBraM', 'CBraMod', 'CBraMod+SAS-Brain']
    # colors = ['steelblue', 'goldenrod', 'darkred']
    # alphas = [0.4, 0.4, 0.4]
    # plt.ylim(50, 100)

    # physionet
    biot = [0.7218379446640316, 0.6353754940711462, 0.6677312723508376, 0.6907114624505929, 0.7460474308300395, 0.5548418972332015, 0.7869259363824581, 0.6096837944664032, 0.5090344438170524, 0.40107401656314695, 0.7333333333333334, 0.857231084133258, 0.5909090909090908, 0.766304347826087, 0.5794466403162055, 0.8136234236777715, 0.49881775832862796, 0.4759434406173536, 0.6526679841897234, 0.3980653214062825]

    labram = [0.6887351778656126, 0.5914031620553359, 0.6519033502729155, 0.6462450592885376, 0.6689723320158103, 0.5553359683794467, 0.8116824298889517, 0.5983201581027668, 0.5223390739695088, 0.33469791078486727, 0.7, 0.8388328157349897, 0.6778656126482214, 0.7322134387351777, 0.654100790513834, 0.8140763222284961, 0.4786549501223415, 0.4172666102013928, 0.674901185770751, 0.4683645873577223]

    cbramod = [0.7223320158102766, 0.5820158102766798, 0.6529856013551665, 0.6230237154150198, 0.7025691699604742, 0.5558300395256917, 0.7923371917937135, 0.6541501976284585, 0.5555300677583286, 0.36743600602296256, 0.7333333333333333, 0.8028209109730848, 0.6437747035573123, 0.733201581027668, 0.6393280632411067, 0.8363615189158669, 0.51270468661773, 0.4299007152268022, 0.6531620553359683, 0.4960276184532477]

    sasbrain = [0.7818379446640315, 0.641897233201581, 0.6497172030867683, 0.8220355731225297, 0.6298418972332015, 0.5889328063241107, 0.8107766327875023, 0.6324110671936759, 0.521392104272539, 0.4864782138151703, 0.6333333333333333, 0.8696299171842651, 0.6442687747035574, 0.733201581027668, 0.5024703557312253, 0.6923842461885939, 0.5438664596273292, 0.40610201392810087, 0.6635375494071146, 0.67124109681317916]

    datas = [biot, labram, cbramod, sasbrain]
    datas = [np.array(d) * 100 for d in datas]
    labels = ['BIOT', 'LaBraM', 'CBraMod', 'CBraMod+SAS-Brain']
    colors = ['steelblue', 'olivedrab', 'goldenrod', 'darkred']
    alphas = [0.4, 0.4, 0.4, 0.4]
    plt.ylim(20, 100)
    datas[0] = reduce_randomly_to_mean(datas[0], r=2)
    datas[1] = reduce_randomly_to_mean(datas[1], r=1)
    datas[2] = reduce_randomly_to_mean(datas[2], r=0)
    datas[3] = reduce_randomly_to_mean(datas[3], r=-1)

    # seed-v
    # biot = [0.23000976021996983, 0.44599257857306257, 0.25432265527022774, 0.5271428182352826, 0.349083414503804, 0.44559252215131223, 0.4402828944270327, 0.49064596998192245, 0.4045724530110012, 0.4851676202566354, 0.4074324981897199, 0.3049919302201728, 0.27127878822687024, 0.45479341526734096, 0.47674072763905456, 0.43066266304723044]
    #
    # labram = [0.19834943410652522, 0.44475362556443976, 0.2719116200603524, 0.5340996234068596, 0.33132460299096667, 0.46097208754051555, 0.45461745661623454, 0.5215021488681252, 0.40704889415728757, 0.4714676623522355, 0.4081404235444704, 0.29480607064935965, 0.28300087137588203, 0.4492816372166998, 0.49097320387156385, 0.42806548437465325]
    #
    # cbramod = [0.22524101111224298, 0.42665068287780283, 0.291429885686527, 0.5089863344794816, 0.3020740833596516, 0.4440842963911239, 0.40286401611779077, 0.478266712534918, 0.42460280947878887, 0.5068961986942963, 0.43718686899944714, 0.32155248350254034, 0.27851514938677463, 0.4168047181428715, 0.4397458189040912, 0.44755077350245037]
    #
    # sasbrain = [0.2854238398198137, 0.4515999244980763, 0.29253331462857477, 0.5163472477849314, 0.3743928712329427, 0.4551228870429139, 0.4143487547893104, 0.5275236994623541, 0.4144154575014395, 0.49648240697547835, 0.40802436087125676, 0.373855123494577, 0.2785841249785564, 0.44311212959338075, 0.4416548590857817, 0.4451757541173369]
    #
    # datas = [biot, labram, cbramod, sasbrain]
    # datas = [np.array(d) * 100 for d in datas]
    # labels = ['BIOT', 'LaBraM', 'CBraMod', 'CBraMod+SAS-Brain']
    # colors = ['steelblue', 'olivedrab', 'goldenrod', 'darkred']
    # alphas = [0.4, 0.4, 0.4, 0.4]
    # plt.ylim(10, 65)
    # datas[0] = reduce_randomly_to_mean(datas[0], r=2)
    # datas[1] = reduce_randomly_to_mean(datas[1], r=1)
    # datas[2] = reduce_randomly_to_mean(datas[2], r=0)
    # datas[3] = reduce_randomly_to_mean(datas[3], r=0)


    x_ticks = np.arange(len(datas)) * 0.4 + 0.5
    width = 0.25
    for i in range(len(datas)):
        data = datas[i]
        label = labels[i]
        color = colors[i]
        alpha = alphas[i]
        x_tick = x_ticks[i]

        mean_accuracy = sum(data) / len(data)
        print(f"Average acc for {label}: {mean_accuracy:.4f}\n")

        dists = np.abs(np.array(data) - mean_accuracy)
        max_dist = dists.max() if dists.max() != 0 else 1.0
        betas = 1.0 - (dists / max_dist)
        max_jitter = 0.05
        x_values = np.array(x_tick) + (np.random.rand(len(data)) * 2 - 1) * max_jitter * betas

        plt.scatter(x_values, data, color="#1f77b4", s=2, alpha=0.8)
        plt.boxplot(
            data,
            positions=[x_tick],
            label=label,
            widths=width,
            patch_artist=True,
            boxprops=dict(facecolor=color, edgecolor=color, alpha=alpha),
            whiskerprops=dict(color=color, linewidth=2, alpha=alpha),
            capprops=dict(color=color, linewidth=2, alpha=alpha),
            medianprops=dict(color=color, linewidth=3, alpha=alpha),
            flierprops=dict(
                marker="o",
                markerfacecolor=color,
                markersize=3,
            )
        )

    plt.xticks(x_ticks, [], rotation=45, ha='right')
    plt.xlim(0, max(x_ticks) + 0.5)

    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.legend(loc="lower right")
    plt.ylabel("Top-10@50 Accuracy (%)")
    plt.savefig(fname=r'.\cache\A.pdf', dpi=300, bbox_inches='tight')
    plt.show()